# Image-Captioning-Transforming-Objects-into-Words
1. Used an encoder-decoder model with Recurrent Neural Networks, embedding layer using Convolutional Neural Network and Long-Short Term Memory networks to build an image captioning model.
2. Used glove embeddings pre-trained on 6 billion words where each word has 200 dimensional feature space.
3. Evaluated the model using different metrics such as Bleu-n, Gleu, Rouge and Beam search.
4. Model achieved a highest bleu-4 score of 0.7 and highest rouge-f score of 0.529.
5. Tech stack used was Tensorflow, Keras, Numpy, NLTK and Python.
